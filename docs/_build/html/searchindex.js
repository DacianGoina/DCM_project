Search.setIndex({"docnames": ["docs_main/consts_values", "docs_main/io_utilities", "docs_main/main", "docs_main/model_utilities", "docs_main/modules", "docs_main/preprocessing_flow", "docs_main/text_preprocessing_utilities", "docs_main/unit_test_model_utilities", "docs_main/unit_test_text_preprocessing_utilities", "docs_model_classes/CountVectorizerFE", "docs_model_classes/Doc2VecFE", "docs_model_classes/FeaturesExtractor", "docs_model_classes/HashingVectorizerFE", "docs_model_classes/ModelManager", "docs_model_classes/ModelWorker", "docs_model_classes/StaticClassifier", "docs_model_classes/TfidfVectorizerFE", "docs_model_classes/modules", "index"], "filenames": ["docs_main\\consts_values.rst", "docs_main\\io_utilities.rst", "docs_main\\main.rst", "docs_main\\model_utilities.rst", "docs_main\\modules.rst", "docs_main\\preprocessing_flow.rst", "docs_main\\text_preprocessing_utilities.rst", "docs_main\\unit_test_model_utilities.rst", "docs_main\\unit_test_text_preprocessing_utilities.rst", "docs_model_classes\\CountVectorizerFE.rst", "docs_model_classes\\Doc2VecFE.rst", "docs_model_classes\\FeaturesExtractor.rst", "docs_model_classes\\HashingVectorizerFE.rst", "docs_model_classes\\ModelManager.rst", "docs_model_classes\\ModelWorker.rst", "docs_model_classes\\StaticClassifier.rst", "docs_model_classes\\TfidfVectorizerFE.rst", "docs_model_classes\\modules.rst", "index.rst"], "titles": ["consts_values module", "io_utilities module", "main module", "model_utilities module", "main", "preprocessing_flow module", "text_preprocessing_utilities module", "unit_test_model_utilities module", "unit_test_text_preprocessing_utilities module", "CountVectorizerFE module", "Doc2VecFE module", "FeaturesExtractor module", "HashingVectorizerFE module", "ModelManager module", "ModelWorker module", "StaticClassifier module", "TfidfVectorizerFE module", "model_classes", "Welcome to MLO-DCM\u2019s documentation!"], "terms": {"src": [1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "main": [1, 3, 5, 6, 7, 8, 14, 18], "export_as_binary_obj": [1, 4], "obj": 1, "output_file_path": [1, 3], "sourc": [1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "function": [1, 3, 5, 6, 7, 8, 13, 14], "serial": 1, "given": [1, 3, 5, 6, 8, 14, 15], "object": [1, 6, 11, 13, 14, 15], "save": [1, 3, 5, 13], "binari": [1, 13], "file": [1, 5, 6, 13, 14], "param": [1, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16], "an": [1, 6, 8], "can": [1, 6, 13], "list": [1, 5, 6, 8, 10, 13, 15], "scaler": 1, "classifi": [1, 13, 14, 15], "path": [1, 3, 5, 13, 14], "where": [1, 3, 5, 9, 12, 13, 15, 16], "json": 1, "return": [1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16], "none": [1, 3, 5, 6, 11, 12, 13], "import_binary_object": [1, 4], "input_file_path": 1, "us": [1, 3, 5, 6, 11, 13, 14, 15], "import": [1, 14], "pickl": 1, "need": 1, "unseri": 1, "python": [1, 3, 5, 6, 9, 10, 12, 13, 14, 15, 16], "case": [1, 5, 6, 8], "error": 1, "dure": 1, "read": [1, 5, 13, 14], "read_raw_data": [1, 4], "main_directory_path": 1, "creat": [1, 5, 6, 8, 13], "datafram": [1, 3, 5, 7], "data": [1, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16], "store": [1, 3, 5], "The": [1, 3, 10, 11, 13], "directori": [1, 5, 13], "ha": [1, 3, 6, 8, 11], "structur": [1, 6], "like": [1, 6], "main_directori": 1, "subdirectory_category1": 1, "subdirectory_category2": 1, "subdirectory_category3": 1, "3": 1, "column": 1, "content": [1, 5, 9, 10, 12, 15, 16], "type": [1, 3, 5, 6, 8], "rtype": [1, 3, 5, 6, 9, 10, 12, 13, 14, 15, 16], "panda": [1, 3, 5, 10, 13], "core": [1, 3, 5], "frame": [1, 3, 5, 10, 13], "read_txt_fil": [1, 4], "file_path": [1, 5, 14], "from": [1, 3, 5, 6, 8, 11, 13, 14, 15], "paramet": [1, 6, 9, 12, 15, 16], "target": [1, 3, 13], "built": [1, 6, 10], "string": [1, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16], "save_dict_to_json_fil": [1, 4], "dictionari": [1, 3, 6, 7, 9, 11, 12, 13, 14, 15, 16], "contain": [1, 3, 6, 8, 13], "pair": [1, 3, 9, 11, 13, 14, 16], "kei": [1, 3, 6, 9, 12, 15, 16], "str_valu": 1, "": [1, 3, 6, 8], "int_valu": 1, "build_data_dictionari": [3, 4], "x_train": 3, "x_test": 3, "y_train": 3, "y_test": 3, "construct": [3, 6, 7], "train": [3, 7, 13, 14, 15], "test": [3, 6, 7, 8, 13, 15], "input": [3, 5, 6, 8, 9, 10, 12, 14, 15, 16], "variabl": [3, 9, 10, 12, 13, 15, 16], "valu": [3, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16], "set": [3, 7, 10, 13], "build": [3, 5, 6, 9, 10, 12, 13, 14, 15, 16], "get_model_evaluation_metr": [3, 4], "confusion_matrix": 3, "comput": [3, 7, 14], "manual": [3, 7], "differ": [3, 7, 8, 15], "metric": [3, 7, 13, 14, 15], "e": [3, 6, 11, 15], "g": [3, 6, 15], "accuraci": [3, 14], "precis": 3, "recal": 3, "specif": [3, 6, 13, 14], "f1": 3, "score": [3, 14], "etc": [3, 15], "onli": [3, 6, 13], "confus": [3, 14, 15], "matrix": [3, 9, 12, 15, 16], "calcul": [3, 15], "model": [3, 5, 6, 10, 13, 14, 15], "mean": 3, "obtain": [3, 13], "shuffle_datafram": [3, 4], "df": [3, 5, 10], "no_of_tim": 3, "1": 3, "shuffl": [3, 7], "x": [3, 7, 11, 13], "time": [3, 7], "row": [3, 10], "number": [3, 5, 6, 8, 14], "split_model_data": [3, 4], "x_data": [3, 13], "y_data": [3, 13], "test_size_valu": 3, "0": 3, "25": 3, "random_state_v": 3, "split": [3, 6, 7, 8, 13], "stratifi": 3, "y": 3, "fashion": 3, "thi": [3, 6, 10, 11, 13, 14, 15], "class": [3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "label": [3, 5, 14, 15], "becaus": 3, "we": [3, 6, 10, 11, 13, 15], "have": [3, 6, 15], "mani": 3, "scope": 3, "being": 3, "uniform": 3, "distribut": 3, "respect": 3, "i": [3, 5, 6, 8, 10, 11, 13, 15], "properli": 3, "ar": [3, 8, 9, 10, 11, 12, 13, 15, 16], "select": 3, "ob": 3, "9": 3, "distinct": 3, "tenth": 3, "proport": 3, "dataset": [3, 13], "repres": [3, 6, 11, 13, 14, 15], "reproduc": 3, "certain": [3, 6], "result": [3, 13, 14, 15], "determinist": 3, "vocabulary_dict_to_json": [3, 4], "provid": [3, 11, 13, 14], "str": [3, 5, 6, 8, 10, 14], "int": 3, "user": [3, 15], "want": [3, 6, 10, 13], "consts_valu": [4, 18], "modul": [4, 17, 18], "io_util": [4, 18], "model_util": [4, 18], "preprocessing_flow": [4, 18], "apply_custom_tokenizer_it": [4, 5], "custom_token": [4, 5], "get_nlp_model": [4, 5], "preprocess_fil": [4, 5], "process_df": [4, 5], "read_preprocess_and_export": [4, 5], "text_preprocessing_util": [4, 18], "get_lowercase_words_from_str": [4, 6], "get_rare_token": [4, 6], "get_spacy_tokens_from_raw_text": [4, 6], "get_str_stopword": [4, 6], "get_str_tokens_freq": [4, 6], "get_str_tokens_freq_for_list": [4, 6], "handle_rare_str_token": [4, 6], "is_6digits_d": [4, 6], "is_str_fract": [4, 6], "is_str_numer": [4, 6, 8], "is_str_valid_d": [4, 6], "is_valid_resourc": [4, 6], "is_valid_url": [4, 6], "lemmatize_spacy_token": [4, 6], "remove_excessive_spac": [4, 6], "remove_spacy_punctu": [4, 6], "remove_str_tokens_len_less_than_threshold": [4, 6], "spacy_tokens_po": [4, 6], "spacy_tokens_to_str_token": [4, 6], "split_and_gather_str_tokens_by_separ": [4, 6], "str_6digits_dates_to_date_tag": [4, 6], "str_currency_to_spoken_word": [4, 6], "str_dates_to_date_tag": [4, 6], "str_emails_to_email_tag": [4, 6], "str_fraction_to_spoken_word": [4, 6], "str_initial_case_to_tag": [4, 6], "str_number_with_separators_to_integer_numb": [4, 6], "str_numeric_values_to_spoken_word": [4, 6], "str_ordinal_numbers_to_spoken_word": [4, 6], "str_remove_common_char": [4, 6], "str_remove_junk_spac": [4, 6], "str_tokens_numbers_with_separators_to_spoken_word": [4, 6], "str_tokens_remove_stopword": [4, 6], "str_tokens_replace_symbol_with_tag": [4, 6], "str_tokens_to_spacy_token": [4, 6], "str_tokens_to_str": [4, 6], "str_urls_to_url_tag": [4, 6], "str_years_to_spoken_word": [4, 6], "to_lowercas": [4, 6], "unit_test_model_util": [4, 18], "unittest": [4, 7, 8], "test_build_data_dictionari": [4, 7], "test_get_model_evaluation_metr": [4, 7], "test_shuffle_datafram": [4, 7], "test_split_model_data": [4, 7], "test_vocabulary_dict_to_json": [4, 7], "unit_test_text_preprocessing_util": [4, 18], "test_get_lowercase_words_from_str": [4, 8], "test_get_rare_token": [4, 8], "test_get_spacy_tokens_from_raw_text": [4, 8], "test_get_str_tokens_freq": [4, 8], "test_get_str_tokens_freq_for_list": [4, 8], "test_handle_rare_str_token": [4, 8], "test_is_6digits_d": [4, 8], "test_is_str_fract": [4, 8], "test_is_str_numer": [4, 8], "test_is_str_valid_d": [4, 8], "test_is_valid_resourc": [4, 8], "test_is_valid_url": [4, 8], "test_lemmatize_spacy_token": [4, 8], "test_remove_excessive_spac": [4, 8], "test_remove_spacy_punctu": [4, 8], "test_remove_str_tokens_len_less_than_threshold": [4, 8], "test_spacy_tokens_po": [4, 8], "test_spacy_tokens_to_str_token": [4, 8], "test_split_and_gather_str_tokens_by_separ": [4, 8], "test_str_6digits_dates_to_date_tag": [4, 8], "test_str_currency_to_spoken_word": [4, 8], "test_str_dates_to_date_tag": [4, 8], "test_str_emails_to_email_tag": [4, 8], "test_str_fraction_to_spoken_word": [4, 8], "test_str_initial_case_to_tag": [4, 8], "test_str_number_with_separators_to_integer_numb": [4, 8], "test_str_numeric_values_to_spoken_word": [4, 8], "test_str_ordinal_numbers_to_spoken_word": [4, 8], "test_str_remove_common_char": [4, 8], "test_str_remove_junk_spac": [4, 8], "test_str_tokens_numbers_with_separators_to_spoken_word": [4, 8], "test_str_tokens_remove_stopword": [4, 8], "test_str_tokens_replace_quote_with_tag": [4, 8], "test_str_tokens_to_spacy_token": [4, 8], "test_str_tokens_to_str": [4, 8], "test_str_urls_to_url_tag": [4, 8], "test_str_years_to_spoken_word": [4, 8], "test_to_lowercas": [4, 8], "raw_text": [5, 14], "nlp_model": [5, 6], "iter": 5, "2": [5, 14], "appli": [5, 6], "token": [5, 6, 8, 11, 14], "over": 5, "raw": [5, 6, 8, 14], "text": [5, 6, 8, 11, 13, 14], "similar": 5, "usag": 5, "epoch": 5, "deep": [5, 15], "learn": [5, 15], "process": [5, 13], "made": 5, "all": [5, 6, 8, 13, 14], "necessari": 5, "transform": [5, 6, 8, 9, 10, 11, 12, 13, 16], "includ": [5, 6, 8, 13, 14], "unprocess": 5, "probabl": [5, 14, 15], "spaci": [5, 6, 8], "lang": [5, 6], "en": 5, "english": 5, "preprocess": [5, 6, 13, 14, 15], "instanc": [5, 6, 11, 13], "nlp": [5, 6], "declar": 5, "requir": [5, 15], "its": 5, "compos": 5, "present": 5, "separ": [5, 6, 8], "preprocessing_iter": 5, "specifi": [5, 8], "mayb": 5, "other": [5, 6, 13, 15], "col": 5, "singl": [5, 6, 10], "directory_path": [5, 13], "output_file_nam": 5, "subdirectori": 5, "func": 5, "csv": [5, 13], "name": [5, 9, 10, 12, 13, 15, 16], "val": 6, "extract": [6, 8], "lowercas": [6, 8], "word": [6, 8, 9, 12, 16], "one": [6, 13], "hous": 6, "without": 6, "charact": 6, "lower": [6, 8], "dict_of_freq": 6, "threshold": [6, 8], "get": [6, 8, 11, 15], "frequenc": [6, 8], "smaller": [6, 8], "than": [6, 8], "lists_of_token": 6, "comparison": 6, "new": [6, 9, 10, 11, 12, 15, 16], "just": [6, 13], "convert": [6, 11, 13, 14], "nativ": 6, "stopword": [6, 8], "exclud": 6, "consid": [6, 13, 14, 15], "replace_with": 6, "unk": 6, "filter": 6, "elimin": [6, 8], "rare": [6, 8], "replac": [6, 8], "remov": [6, 8], "els": 6, "item": 6, "verifi": 6, "calendar": [6, 8], "date": [6, 8], "6": [6, 8], "digit": [6, 8], "format": [6, 13, 14], "14": 6, "05": 6, "93": 6, "refer": [6, 15], "year": [6, 8], "bool": 6, "true": 6, "fals": [6, 13], "otherwis": 6, "valid": [6, 8], "fraction": [6, 8], "numer": [6, 8, 10, 11, 13, 14], "check": [6, 8], "url": [6, 8], "small": [6, 8], "notat": [6, 8], "kind": 6, "resourc": 6, "am": 6, "arc": 6, "nasa": 6, "gov": 6, "uri": 6, "lemmat": 6, "everi": [6, 13, 15], "element": [6, 10], "initi": [6, 10], "base": [6, 7, 8, 9, 10, 11, 12, 14, 15, 16], "form": [6, 8], "excess": 6, "white": 6, "space": [6, 8], "begin": 6, "end": 6, "punctuat": [6, 8], "threshold_valu": 6, "length": [6, 8], "minim": 6, "modifi": 6, "tupl": [6, 8, 13, 14], "posit": [6, 8, 10, 11], "equival": 6, "entiti": [6, 11], "tech": 6, "media": 6, "which": 6, "becom": 6, "after": [6, 11], "c_date": [6, 8], "tag": [6, 8], "apparit": 6, "currenc": [6, 8], "reconstruct": 6, "instead": [6, 11], "email": [6, 8], "address": 6, "constant": 6, "produc": 6, "some": [6, 11], "chain": 6, "half": 6, "letter": 6, "f": 6, "appear": [6, 8], "comma": [6, 8], "integ": [6, 8, 14], "10": 6, "500": 6, "205": 6, "10500205": 6, "ordin": [6, 8], "common": [6, 8], "char": [6, 8], "junk": [6, 8], "spoken": [6, 8], "append": 6, "them": [6, 14, 15], "ten": 6, "million": 6, "five": 6, "hundr": 6, "thousand": 6, "two": 6, "defin": 6, "also": 6, "symbol": [6, 8], "mention": 6, "cat": 6, "quot": 6, "what": 6, "methodnam": [7, 8], "runtest": [7, 8], "testcas": [7, 8], "unit": [7, 8], "multipl": 8, "mix": 8, "upper": 8, "thst": 8, "invalid": 8, "when": [8, 13], "non": 8, "lemat": 8, "see": 8, "null": 8, "model_class": [9, 10, 11, 12, 13, 14, 15, 16, 18], "featuresextractor": [9, 10, 12, 13, 16, 17, 18], "get_extractor_param": [9, 10, 11, 12, 16, 17], "getter": [9, 10, 11, 12, 15, 16], "copi": [9, 10, 11, 12, 15, 16], "get_vocabulari": [9, 11, 12, 16, 17], "method": [9, 10, 11, 12, 13, 15, 16], "uniqu": [9, 12, 16], "featur": [9, 10, 11, 12, 13, 14, 15, 16], "correspond": [9, 12, 15, 16], "indic": [9, 12, 16], "set_extractor_param": [9, 10, 11, 12, 16, 17], "new_param": [9, 10, 11, 12, 15, 16], "setter": [9, 11, 12, 15, 16], "short_str": [9, 10, 12, 15, 16, 17], "transform_data": [9, 10, 11, 12, 16, 17], "For": 10, "doc2vec": 10, "extractor": [10, 11, 13, 14], "cannot": 10, "wai": [10, 15], "If": 10, "you": 10, "chang": 10, "mandatori": 10, "retrain": 10, "again": 10, "so": 10, "would": 10, "seri": [10, 13], "scale": 10, "capabl": 11, "later": [11, 13], "classif": [11, 13, 14], "receiv": [11, 13, 14], "sklearn": [11, 15], "act": 11, "abstract": 11, "directli": 11, "deriv": 11, "get_data": [11, 17], "pure": 11, "virtual": [11, 12], "vocabulari": 11, "set_data": [11, 17], "new_data": 11, "pass": [11, 15], "assum": [11, 13, 15], "been": 11, "alreadi": [11, 15], "fit": [11, 13, 15], "work": [13, 14, 15], "manag": 13, "along": 13, "step": 13, "flow": 13, "follow": 13, "our": 13, "origin": 13, "concret": 13, "reus": 13, "stage": 13, "cross": 13, "product": 13, "logic": 13, "features_extractor": 13, "evalu": [13, 14], "observ": 13, "onc": 13, "per": 13, "ani": 13, "thu": 13, "cl": 13, "k": 13, "locat": [13, 14], "aim": 13, "persist": 13, "predict": [13, 14, 15, 17], "request": 13, "build_classifi": [13, 17], "initialis": 13, "build_features_extractor": [13, 17], "get_classifier_to_extractor_str": [13, 17], "classifier_nam": [13, 14], "features_extractor_nam": 13, "manager_execut": [13, 17], "input_data_path": 13, "output_objects_path": 13, "save_model_obj": 13, "aggreg": 13, "oper": 13, "root": [13, 14], "pf": 13, "should": 13, "option": 13, "model_fit_train_predict": [13, 17], "save_model_object": 13, "compon": 13, "run": 13, "independ": 13, "staticclassifi": [13, 17, 18], "amd": 13, "reverse_classifier_to_extractor_str": [13, 17], "compound_nam": 13, "compound": 13, "revers": 13, "engin": 13, "save_model_compon": [13, 17], "object_nam": 13, "worker": 14, "servant": 14, "It": 14, "predefin": 14, "vote": 14, "system": 14, "evaluate_classifi": [14, 17], "perform": 14, "matric": 14, "d": 14, "dict": 14, "associ": 14, "import_classifi": [14, 17], "extractor_nam": 14, "import_features_extractor": [14, 17], "import_model_object": [14, 17], "perform_predict": [14, 17], "processed_text": 14, "insid": 14, "addit": 14, "inform": 14, "top": 14, "predict_input_from_fil": [14, 17], "preprocess_input": [14, 17], "join": 14, "voting_system": [14, 17], "dict_with_predict": 14, "n_highest_prob": 14, "classifier_extractor_nam": 14, "highest": 14, "occurr": 14, "occur": 14, "worker_execut": [14, 17], "call": 14, "static": 15, "context": 15, "classic": 15, "solver": 15, "randomforestclassifi": 15, "xgboostclassifi": 15, "svm": 15, "heavili": 15, "neural": 15, "network": 15, "usual": 15, "complex": 15, "architectur": 15, "thing": 15, "must": 15, "wrapper": 15, "packag": 15, "incorpor": 15, "implement": 15, "allow": 15, "proper": 15, "model_classifi": 15, "fit_train_evalu": [15, 17], "dict_data": 15, "get_confusion_matrix": [15, 17], "get_model_class": [15, 17], "get_model_param": [15, 17], "data_point": 15, "predict_prob": [15, 17], "point": 15, "set_model_param": [15, 17], "map": 15, "n_estim": 15, "200": 15, "countvectorizerf": [17, 18], "doc2vecf": [17, 18], "hashingvectorizerf": [17, 18], "modelmanag": [17, 18], "modelwork": [17, 18], "tfidfvectorizerf": [17, 18], "index": 18, "search": 18, "page": 18}, "objects": {"src.main": [[0, 0, 0, "-", "consts_values"], [1, 0, 0, "-", "io_utilities"], [2, 0, 0, "-", "main"], [3, 0, 0, "-", "model_utilities"], [5, 0, 0, "-", "preprocessing_flow"], [6, 0, 0, "-", "text_preprocessing_utilities"], [7, 0, 0, "-", "unit_test_model_utilities"], [8, 0, 0, "-", "unit_test_text_preprocessing_utilities"]], "src.main.io_utilities": [[1, 1, 1, "", "export_as_binary_obj"], [1, 1, 1, "", "import_binary_object"], [1, 1, 1, "", "read_raw_data"], [1, 1, 1, "", "read_txt_file"], [1, 1, 1, "", "save_dict_to_json_file"]], "src.main.model_utilities": [[3, 1, 1, "", "build_data_dictionary"], [3, 1, 1, "", "get_model_evaluation_metrics"], [3, 1, 1, "", "shuffle_dataframe"], [3, 1, 1, "", "split_model_data"], [3, 1, 1, "", "vocabulary_dict_to_json"]], "src.main.preprocessing_flow": [[5, 1, 1, "", "apply_custom_tokenizer_iteratively"], [5, 1, 1, "", "custom_tokenizer"], [5, 1, 1, "", "get_nlp_model"], [5, 1, 1, "", "preprocess_file"], [5, 1, 1, "", "process_df"], [5, 1, 1, "", "read_preprocess_and_export"]], "src.main.text_preprocessing_utilities": [[6, 1, 1, "", "get_lowercase_words_from_str"], [6, 1, 1, "", "get_rare_tokens"], [6, 1, 1, "", "get_spacy_tokens_from_raw_text"], [6, 1, 1, "", "get_str_stopwords"], [6, 1, 1, "", "get_str_tokens_freq"], [6, 1, 1, "", "get_str_tokens_freq_for_lists"], [6, 1, 1, "", "handle_rare_str_tokens"], [6, 1, 1, "", "is_6digits_date"], [6, 1, 1, "", "is_str_fraction"], [6, 1, 1, "", "is_str_numeric"], [6, 1, 1, "", "is_str_valid_date"], [6, 1, 1, "", "is_valid_resource"], [6, 1, 1, "", "is_valid_url"], [6, 1, 1, "", "lemmatize_spacy_tokens"], [6, 1, 1, "", "remove_excessive_space"], [6, 1, 1, "", "remove_spacy_punctuations"], [6, 1, 1, "", "remove_str_tokens_len_less_than_threshold"], [6, 1, 1, "", "spacy_tokens_pos"], [6, 1, 1, "", "spacy_tokens_to_str_tokens"], [6, 1, 1, "", "split_and_gather_str_tokens_by_separator"], [6, 1, 1, "", "str_6digits_dates_to_date_tag"], [6, 1, 1, "", "str_currency_to_spoken_words"], [6, 1, 1, "", "str_dates_to_date_tag"], [6, 1, 1, "", "str_emails_to_email_tag"], [6, 1, 1, "", "str_fraction_to_spoken_words"], [6, 1, 1, "", "str_initial_case_to_tag"], [6, 1, 1, "", "str_number_with_separators_to_integer_number"], [6, 1, 1, "", "str_numeric_values_to_spoken_words"], [6, 1, 1, "", "str_ordinal_numbers_to_spoken_words"], [6, 1, 1, "", "str_remove_common_chars"], [6, 1, 1, "", "str_remove_junk_spaces"], [6, 1, 1, "", "str_tokens_numbers_with_separators_to_spoken_words"], [6, 1, 1, "", "str_tokens_remove_stopwords"], [6, 1, 1, "", "str_tokens_replace_symbol_with_tag"], [6, 1, 1, "", "str_tokens_to_spacy_tokens"], [6, 1, 1, "", "str_tokens_to_str"], [6, 1, 1, "", "str_urls_to_url_tag"], [6, 1, 1, "", "str_years_to_spoken_words"], [6, 1, 1, "", "to_lowercase"]], "src.main.unit_test_model_utilities": [[7, 2, 1, "", "UnitTests"]], "src.main.unit_test_model_utilities.UnitTests": [[7, 3, 1, "", "test_build_data_dictionary"], [7, 3, 1, "", "test_get_model_evaluation_metrics"], [7, 3, 1, "", "test_shuffle_dataframe"], [7, 3, 1, "", "test_split_model_data"], [7, 3, 1, "", "test_vocabulary_dict_to_json"]], "src.main.unit_test_text_preprocessing_utilities": [[8, 2, 1, "", "UnitTests"]], "src.main.unit_test_text_preprocessing_utilities.UnitTests": [[8, 3, 1, "", "test_get_lowercase_words_from_str"], [8, 3, 1, "", "test_get_rare_tokens"], [8, 3, 1, "", "test_get_spacy_tokens_from_raw_text"], [8, 3, 1, "", "test_get_str_tokens_freq"], [8, 3, 1, "", "test_get_str_tokens_freq_for_lists"], [8, 3, 1, "", "test_handle_rare_str_tokens"], [8, 3, 1, "", "test_is_6digits_date"], [8, 3, 1, "", "test_is_str_fraction"], [8, 3, 1, "", "test_is_str_numeric"], [8, 3, 1, "", "test_is_str_valid_date"], [8, 3, 1, "", "test_is_valid_resource"], [8, 3, 1, "", "test_is_valid_url"], [8, 3, 1, "", "test_lemmatize_spacy_tokens"], [8, 3, 1, "", "test_remove_excessive_space"], [8, 3, 1, "", "test_remove_spacy_punctuations"], [8, 3, 1, "", "test_remove_str_tokens_len_less_than_threshold"], [8, 3, 1, "", "test_spacy_tokens_pos"], [8, 3, 1, "", "test_spacy_tokens_to_str_tokens"], [8, 3, 1, "", "test_split_and_gather_str_tokens_by_separator"], [8, 3, 1, "", "test_str_6digits_dates_to_date_tag"], [8, 3, 1, "", "test_str_currency_to_spoken_words"], [8, 3, 1, "", "test_str_dates_to_date_tag"], [8, 3, 1, "", "test_str_emails_to_email_tag"], [8, 3, 1, "", "test_str_fraction_to_spoken_words"], [8, 3, 1, "", "test_str_initial_case_to_tag"], [8, 3, 1, "", "test_str_number_with_separators_to_integer_number"], [8, 3, 1, "", "test_str_numeric_values_to_spoken_words"], [8, 3, 1, "", "test_str_ordinal_numbers_to_spoken_words"], [8, 3, 1, "", "test_str_remove_common_chars"], [8, 3, 1, "", "test_str_remove_junk_spaces"], [8, 3, 1, "", "test_str_tokens_numbers_with_separators_to_spoken_words"], [8, 3, 1, "", "test_str_tokens_remove_stopwords"], [8, 3, 1, "", "test_str_tokens_replace_quote_with_tag"], [8, 3, 1, "", "test_str_tokens_to_spacy_tokens"], [8, 3, 1, "", "test_str_tokens_to_str"], [8, 3, 1, "", "test_str_urls_to_url_tag"], [8, 3, 1, "", "test_str_years_to_spoken_words"], [8, 3, 1, "", "test_to_lowercase"]], "src.model_classes": [[9, 0, 0, "-", "CountVectorizerFE"], [10, 0, 0, "-", "Doc2VecFE"], [11, 0, 0, "-", "FeaturesExtractor"], [12, 0, 0, "-", "HashingVectorizerFE"], [13, 0, 0, "-", "ModelManager"], [14, 0, 0, "-", "ModelWorker"], [15, 0, 0, "-", "StaticClassifier"], [16, 0, 0, "-", "TfidfVectorizerFE"]], "src.model_classes.CountVectorizerFE": [[9, 2, 1, "", "CountVectorizerFE"]], "src.model_classes.CountVectorizerFE.CountVectorizerFE": [[9, 3, 1, "", "get_extractor_params"], [9, 3, 1, "", "get_vocabulary"], [9, 3, 1, "", "set_extractor_params"], [9, 3, 1, "", "short_str"], [9, 3, 1, "", "transform_data"]], "src.model_classes.Doc2VecFE": [[10, 2, 1, "", "Doc2VecFE"]], "src.model_classes.Doc2VecFE.Doc2VecFE": [[10, 3, 1, "", "get_extractor_params"], [10, 3, 1, "", "set_extractor_params"], [10, 3, 1, "", "short_str"], [10, 3, 1, "", "transform_data"]], "src.model_classes.FeaturesExtractor": [[11, 2, 1, "", "FeaturesExtractor"]], "src.model_classes.FeaturesExtractor.FeaturesExtractor": [[11, 3, 1, "", "get_data"], [11, 3, 1, "", "get_extractor_params"], [11, 3, 1, "", "get_vocabulary"], [11, 3, 1, "", "set_data"], [11, 3, 1, "", "set_extractor_params"], [11, 3, 1, "", "transform_data"]], "src.model_classes.HashingVectorizerFE": [[12, 2, 1, "", "HashingVectorizerFE"]], "src.model_classes.HashingVectorizerFE.HashingVectorizerFE": [[12, 3, 1, "", "get_extractor_params"], [12, 3, 1, "", "get_vocabulary"], [12, 3, 1, "", "set_extractor_params"], [12, 3, 1, "", "short_str"], [12, 3, 1, "", "transform_data"]], "src.model_classes.ModelManager": [[13, 1, 1, "", "build_classifiers"], [13, 1, 1, "", "build_features_extractors"], [13, 1, 1, "", "get_classifier_to_extractor_str"], [13, 1, 1, "", "manager_execute"], [13, 1, 1, "", "model_fit_train_predict"], [13, 1, 1, "", "reverse_classifier_to_extractor_str"], [13, 1, 1, "", "save_model_component"]], "src.model_classes.ModelWorker": [[14, 1, 1, "", "evaluate_classifiers"], [14, 1, 1, "", "import_classifiers"], [14, 1, 1, "", "import_features_extractors"], [14, 1, 1, "", "import_model_objects"], [14, 1, 1, "", "perform_prediction"], [14, 1, 1, "", "predict_input_from_file"], [14, 1, 1, "", "preprocess_input"], [14, 1, 1, "", "voting_system"], [14, 1, 1, "", "worker_execute"]], "src.model_classes.StaticClassifier": [[15, 2, 1, "", "StaticClassifier"]], "src.model_classes.StaticClassifier.StaticClassifier": [[15, 3, 1, "", "fit_train_evaluate"], [15, 3, 1, "", "get_confusion_matrix"], [15, 3, 1, "", "get_model_classes"], [15, 3, 1, "", "get_model_params"], [15, 3, 1, "", "predict"], [15, 3, 1, "", "predict_probabilities"], [15, 3, 1, "", "set_model_params"], [15, 3, 1, "", "short_str"]], "src.model_classes.TfidfVectorizerFE": [[16, 2, 1, "", "TfidfVectorizerFE"]], "src.model_classes.TfidfVectorizerFE.TfidfVectorizerFE": [[16, 3, 1, "", "get_extractor_params"], [16, 3, 1, "", "get_vocabulary"], [16, 3, 1, "", "set_extractor_params"], [16, 3, 1, "", "short_str"], [16, 3, 1, "", "transform_data"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"]}, "titleterms": {"consts_valu": 0, "modul": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "io_util": 1, "main": [2, 4], "model_util": 3, "preprocessing_flow": 5, "text_preprocessing_util": 6, "unit_test_model_util": 7, "unit_test_text_preprocessing_util": 8, "countvectorizerf": 9, "doc2vecf": 10, "featuresextractor": 11, "hashingvectorizerf": 12, "modelmanag": 13, "modelwork": 14, "staticclassifi": 15, "tfidfvectorizerf": 16, "model_class": 17, "welcom": 18, "mlo": 18, "dcm": 18, "": 18, "document": 18, "content": 18, "indic": 18, "tabl": 18}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.todo": 2, "sphinx": 58}, "alltitles": {"consts_values module": [[0, "module-src.main.consts_values"]], "io_utilities module": [[1, "module-src.main.io_utilities"]], "main module": [[2, "module-src.main.main"]], "model_utilities module": [[3, "module-src.main.model_utilities"]], "main": [[4, "main"]], "preprocessing_flow module": [[5, "module-src.main.preprocessing_flow"]], "text_preprocessing_utilities module": [[6, "module-src.main.text_preprocessing_utilities"]], "unit_test_model_utilities module": [[7, "module-src.main.unit_test_model_utilities"]], "unit_test_text_preprocessing_utilities module": [[8, "module-src.main.unit_test_text_preprocessing_utilities"]], "CountVectorizerFE module": [[9, "module-src.model_classes.CountVectorizerFE"]], "Doc2VecFE module": [[10, "module-src.model_classes.Doc2VecFE"]], "FeaturesExtractor module": [[11, "module-src.model_classes.FeaturesExtractor"]], "HashingVectorizerFE module": [[12, "module-src.model_classes.HashingVectorizerFE"]], "ModelManager module": [[13, "module-src.model_classes.ModelManager"]], "ModelWorker module": [[14, "module-src.model_classes.ModelWorker"]], "StaticClassifier module": [[15, "module-src.model_classes.StaticClassifier"]], "TfidfVectorizerFE module": [[16, "module-src.model_classes.TfidfVectorizerFE"]], "model_classes": [[17, "model-classes"]], "Welcome to MLO-DCM\u2019s documentation!": [[18, "welcome-to-mlo-dcm-s-documentation"]], "Contents:": [[18, null]], "Indices and tables": [[18, "indices-and-tables"]]}, "indexentries": {"module": [[0, "module-src.main.consts_values"], [1, "module-src.main.io_utilities"], [2, "module-src.main.main"], [3, "module-src.main.model_utilities"], [5, "module-src.main.preprocessing_flow"], [6, "module-src.main.text_preprocessing_utilities"], [7, "module-src.main.unit_test_model_utilities"], [8, "module-src.main.unit_test_text_preprocessing_utilities"], [9, "module-src.model_classes.CountVectorizerFE"], [10, "module-src.model_classes.Doc2VecFE"], [11, "module-src.model_classes.FeaturesExtractor"], [12, "module-src.model_classes.HashingVectorizerFE"], [13, "module-src.model_classes.ModelManager"], [14, "module-src.model_classes.ModelWorker"], [15, "module-src.model_classes.StaticClassifier"], [16, "module-src.model_classes.TfidfVectorizerFE"]], "src.main.consts_values": [[0, "module-src.main.consts_values"]], "export_as_binary_obj() (in module src.main.io_utilities)": [[1, "src.main.io_utilities.export_as_binary_obj"]], "import_binary_object() (in module src.main.io_utilities)": [[1, "src.main.io_utilities.import_binary_object"]], "read_raw_data() (in module src.main.io_utilities)": [[1, "src.main.io_utilities.read_raw_data"]], "read_txt_file() (in module src.main.io_utilities)": [[1, "src.main.io_utilities.read_txt_file"]], "save_dict_to_json_file() (in module src.main.io_utilities)": [[1, "src.main.io_utilities.save_dict_to_json_file"]], "src.main.io_utilities": [[1, "module-src.main.io_utilities"]], "src.main.main": [[2, "module-src.main.main"]], "build_data_dictionary() (in module src.main.model_utilities)": [[3, "src.main.model_utilities.build_data_dictionary"]], "get_model_evaluation_metrics() (in module src.main.model_utilities)": [[3, "src.main.model_utilities.get_model_evaluation_metrics"]], "shuffle_dataframe() (in module src.main.model_utilities)": [[3, "src.main.model_utilities.shuffle_dataframe"]], "split_model_data() (in module src.main.model_utilities)": [[3, "src.main.model_utilities.split_model_data"]], "src.main.model_utilities": [[3, "module-src.main.model_utilities"]], "vocabulary_dict_to_json() (in module src.main.model_utilities)": [[3, "src.main.model_utilities.vocabulary_dict_to_json"]], "apply_custom_tokenizer_iteratively() (in module src.main.preprocessing_flow)": [[5, "src.main.preprocessing_flow.apply_custom_tokenizer_iteratively"]], "custom_tokenizer() (in module src.main.preprocessing_flow)": [[5, "src.main.preprocessing_flow.custom_tokenizer"]], "get_nlp_model() (in module src.main.preprocessing_flow)": [[5, "src.main.preprocessing_flow.get_nlp_model"]], "preprocess_file() (in module src.main.preprocessing_flow)": [[5, "src.main.preprocessing_flow.preprocess_file"]], "process_df() (in module src.main.preprocessing_flow)": [[5, "src.main.preprocessing_flow.process_df"]], "read_preprocess_and_export() (in module src.main.preprocessing_flow)": [[5, "src.main.preprocessing_flow.read_preprocess_and_export"]], "src.main.preprocessing_flow": [[5, "module-src.main.preprocessing_flow"]], "get_lowercase_words_from_str() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.get_lowercase_words_from_str"]], "get_rare_tokens() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.get_rare_tokens"]], "get_spacy_tokens_from_raw_text() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.get_spacy_tokens_from_raw_text"]], "get_str_stopwords() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.get_str_stopwords"]], "get_str_tokens_freq() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.get_str_tokens_freq"]], "get_str_tokens_freq_for_lists() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.get_str_tokens_freq_for_lists"]], "handle_rare_str_tokens() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.handle_rare_str_tokens"]], "is_6digits_date() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.is_6digits_date"]], "is_str_fraction() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.is_str_fraction"]], "is_str_numeric() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.is_str_numeric"]], "is_str_valid_date() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.is_str_valid_date"]], "is_valid_resource() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.is_valid_resource"]], "is_valid_url() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.is_valid_url"]], "lemmatize_spacy_tokens() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.lemmatize_spacy_tokens"]], "remove_excessive_space() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.remove_excessive_space"]], "remove_spacy_punctuations() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.remove_spacy_punctuations"]], "remove_str_tokens_len_less_than_threshold() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.remove_str_tokens_len_less_than_threshold"]], "spacy_tokens_pos() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.spacy_tokens_pos"]], "spacy_tokens_to_str_tokens() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.spacy_tokens_to_str_tokens"]], "split_and_gather_str_tokens_by_separator() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.split_and_gather_str_tokens_by_separator"]], "src.main.text_preprocessing_utilities": [[6, "module-src.main.text_preprocessing_utilities"]], "str_6digits_dates_to_date_tag() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_6digits_dates_to_date_tag"]], "str_currency_to_spoken_words() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_currency_to_spoken_words"]], "str_dates_to_date_tag() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_dates_to_date_tag"]], "str_emails_to_email_tag() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_emails_to_email_tag"]], "str_fraction_to_spoken_words() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_fraction_to_spoken_words"]], "str_initial_case_to_tag() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_initial_case_to_tag"]], "str_number_with_separators_to_integer_number() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_number_with_separators_to_integer_number"]], "str_numeric_values_to_spoken_words() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_numeric_values_to_spoken_words"]], "str_ordinal_numbers_to_spoken_words() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_ordinal_numbers_to_spoken_words"]], "str_remove_common_chars() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_remove_common_chars"]], "str_remove_junk_spaces() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_remove_junk_spaces"]], "str_tokens_numbers_with_separators_to_spoken_words() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_tokens_numbers_with_separators_to_spoken_words"]], "str_tokens_remove_stopwords() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_tokens_remove_stopwords"]], "str_tokens_replace_symbol_with_tag() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_tokens_replace_symbol_with_tag"]], "str_tokens_to_spacy_tokens() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_tokens_to_spacy_tokens"]], "str_tokens_to_str() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_tokens_to_str"]], "str_urls_to_url_tag() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_urls_to_url_tag"]], "str_years_to_spoken_words() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.str_years_to_spoken_words"]], "to_lowercase() (in module src.main.text_preprocessing_utilities)": [[6, "src.main.text_preprocessing_utilities.to_lowercase"]], "unittests (class in src.main.unit_test_model_utilities)": [[7, "src.main.unit_test_model_utilities.UnitTests"]], "src.main.unit_test_model_utilities": [[7, "module-src.main.unit_test_model_utilities"]], "test_build_data_dictionary() (src.main.unit_test_model_utilities.unittests method)": [[7, "src.main.unit_test_model_utilities.UnitTests.test_build_data_dictionary"]], "test_get_model_evaluation_metrics() (src.main.unit_test_model_utilities.unittests method)": [[7, "src.main.unit_test_model_utilities.UnitTests.test_get_model_evaluation_metrics"]], "test_shuffle_dataframe() (src.main.unit_test_model_utilities.unittests method)": [[7, "src.main.unit_test_model_utilities.UnitTests.test_shuffle_dataframe"]], "test_split_model_data() (src.main.unit_test_model_utilities.unittests method)": [[7, "src.main.unit_test_model_utilities.UnitTests.test_split_model_data"]], "test_vocabulary_dict_to_json() (src.main.unit_test_model_utilities.unittests method)": [[7, "src.main.unit_test_model_utilities.UnitTests.test_vocabulary_dict_to_json"]], "unittests (class in src.main.unit_test_text_preprocessing_utilities)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests"]], "src.main.unit_test_text_preprocessing_utilities": [[8, "module-src.main.unit_test_text_preprocessing_utilities"]], "test_get_lowercase_words_from_str() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_get_lowercase_words_from_str"]], "test_get_rare_tokens() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_get_rare_tokens"]], "test_get_spacy_tokens_from_raw_text() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_get_spacy_tokens_from_raw_text"]], "test_get_str_tokens_freq() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_get_str_tokens_freq"]], "test_get_str_tokens_freq_for_lists() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_get_str_tokens_freq_for_lists"]], "test_handle_rare_str_tokens() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_handle_rare_str_tokens"]], "test_is_6digits_date() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_is_6digits_date"]], "test_is_str_fraction() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_is_str_fraction"]], "test_is_str_numeric() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_is_str_numeric"]], "test_is_str_valid_date() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_is_str_valid_date"]], "test_is_valid_resource() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_is_valid_resource"]], "test_is_valid_url() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_is_valid_url"]], "test_lemmatize_spacy_tokens() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_lemmatize_spacy_tokens"]], "test_remove_excessive_space() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_remove_excessive_space"]], "test_remove_spacy_punctuations() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_remove_spacy_punctuations"]], "test_remove_str_tokens_len_less_than_threshold() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_remove_str_tokens_len_less_than_threshold"]], "test_spacy_tokens_pos() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_spacy_tokens_pos"]], "test_spacy_tokens_to_str_tokens() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_spacy_tokens_to_str_tokens"]], "test_split_and_gather_str_tokens_by_separator() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_split_and_gather_str_tokens_by_separator"]], "test_str_6digits_dates_to_date_tag() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_6digits_dates_to_date_tag"]], "test_str_currency_to_spoken_words() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_currency_to_spoken_words"]], "test_str_dates_to_date_tag() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_dates_to_date_tag"]], "test_str_emails_to_email_tag() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_emails_to_email_tag"]], "test_str_fraction_to_spoken_words() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_fraction_to_spoken_words"]], "test_str_initial_case_to_tag() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_initial_case_to_tag"]], "test_str_number_with_separators_to_integer_number() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_number_with_separators_to_integer_number"]], "test_str_numeric_values_to_spoken_words() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_numeric_values_to_spoken_words"]], "test_str_ordinal_numbers_to_spoken_words() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_ordinal_numbers_to_spoken_words"]], "test_str_remove_common_chars() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_remove_common_chars"]], "test_str_remove_junk_spaces() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_remove_junk_spaces"]], "test_str_tokens_numbers_with_separators_to_spoken_words() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_tokens_numbers_with_separators_to_spoken_words"]], "test_str_tokens_remove_stopwords() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_tokens_remove_stopwords"]], "test_str_tokens_replace_quote_with_tag() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_tokens_replace_quote_with_tag"]], "test_str_tokens_to_spacy_tokens() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_tokens_to_spacy_tokens"]], "test_str_tokens_to_str() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_tokens_to_str"]], "test_str_urls_to_url_tag() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_urls_to_url_tag"]], "test_str_years_to_spoken_words() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_str_years_to_spoken_words"]], "test_to_lowercase() (src.main.unit_test_text_preprocessing_utilities.unittests method)": [[8, "src.main.unit_test_text_preprocessing_utilities.UnitTests.test_to_lowercase"]], "countvectorizerfe (class in src.model_classes.countvectorizerfe)": [[9, "src.model_classes.CountVectorizerFE.CountVectorizerFE"]], "get_extractor_params() (src.model_classes.countvectorizerfe.countvectorizerfe method)": [[9, "src.model_classes.CountVectorizerFE.CountVectorizerFE.get_extractor_params"]], "get_vocabulary() (src.model_classes.countvectorizerfe.countvectorizerfe method)": [[9, "src.model_classes.CountVectorizerFE.CountVectorizerFE.get_vocabulary"]], "set_extractor_params() (src.model_classes.countvectorizerfe.countvectorizerfe method)": [[9, "src.model_classes.CountVectorizerFE.CountVectorizerFE.set_extractor_params"]], "short_str() (src.model_classes.countvectorizerfe.countvectorizerfe method)": [[9, "src.model_classes.CountVectorizerFE.CountVectorizerFE.short_str"]], "src.model_classes.countvectorizerfe": [[9, "module-src.model_classes.CountVectorizerFE"]], "transform_data() (src.model_classes.countvectorizerfe.countvectorizerfe method)": [[9, "src.model_classes.CountVectorizerFE.CountVectorizerFE.transform_data"]], "doc2vecfe (class in src.model_classes.doc2vecfe)": [[10, "src.model_classes.Doc2VecFE.Doc2VecFE"]], "get_extractor_params() (src.model_classes.doc2vecfe.doc2vecfe method)": [[10, "src.model_classes.Doc2VecFE.Doc2VecFE.get_extractor_params"]], "set_extractor_params() (src.model_classes.doc2vecfe.doc2vecfe method)": [[10, "src.model_classes.Doc2VecFE.Doc2VecFE.set_extractor_params"]], "short_str() (src.model_classes.doc2vecfe.doc2vecfe method)": [[10, "src.model_classes.Doc2VecFE.Doc2VecFE.short_str"]], "src.model_classes.doc2vecfe": [[10, "module-src.model_classes.Doc2VecFE"]], "transform_data() (src.model_classes.doc2vecfe.doc2vecfe method)": [[10, "src.model_classes.Doc2VecFE.Doc2VecFE.transform_data"]], "featuresextractor (class in src.model_classes.featuresextractor)": [[11, "src.model_classes.FeaturesExtractor.FeaturesExtractor"]], "get_data() (src.model_classes.featuresextractor.featuresextractor method)": [[11, "src.model_classes.FeaturesExtractor.FeaturesExtractor.get_data"]], "get_extractor_params() (src.model_classes.featuresextractor.featuresextractor method)": [[11, "src.model_classes.FeaturesExtractor.FeaturesExtractor.get_extractor_params"]], "get_vocabulary() (src.model_classes.featuresextractor.featuresextractor method)": [[11, "src.model_classes.FeaturesExtractor.FeaturesExtractor.get_vocabulary"]], "set_data() (src.model_classes.featuresextractor.featuresextractor method)": [[11, "src.model_classes.FeaturesExtractor.FeaturesExtractor.set_data"]], "set_extractor_params() (src.model_classes.featuresextractor.featuresextractor method)": [[11, "src.model_classes.FeaturesExtractor.FeaturesExtractor.set_extractor_params"]], "src.model_classes.featuresextractor": [[11, "module-src.model_classes.FeaturesExtractor"]], "transform_data() (src.model_classes.featuresextractor.featuresextractor method)": [[11, "src.model_classes.FeaturesExtractor.FeaturesExtractor.transform_data"]], "hashingvectorizerfe (class in src.model_classes.hashingvectorizerfe)": [[12, "src.model_classes.HashingVectorizerFE.HashingVectorizerFE"]], "get_extractor_params() (src.model_classes.hashingvectorizerfe.hashingvectorizerfe method)": [[12, "src.model_classes.HashingVectorizerFE.HashingVectorizerFE.get_extractor_params"]], "get_vocabulary() (src.model_classes.hashingvectorizerfe.hashingvectorizerfe method)": [[12, "src.model_classes.HashingVectorizerFE.HashingVectorizerFE.get_vocabulary"]], "set_extractor_params() (src.model_classes.hashingvectorizerfe.hashingvectorizerfe method)": [[12, "src.model_classes.HashingVectorizerFE.HashingVectorizerFE.set_extractor_params"]], "short_str() (src.model_classes.hashingvectorizerfe.hashingvectorizerfe method)": [[12, "src.model_classes.HashingVectorizerFE.HashingVectorizerFE.short_str"]], "src.model_classes.hashingvectorizerfe": [[12, "module-src.model_classes.HashingVectorizerFE"]], "transform_data() (src.model_classes.hashingvectorizerfe.hashingvectorizerfe method)": [[12, "src.model_classes.HashingVectorizerFE.HashingVectorizerFE.transform_data"]], "build_classifiers() (in module src.model_classes.modelmanager)": [[13, "src.model_classes.ModelManager.build_classifiers"]], "build_features_extractors() (in module src.model_classes.modelmanager)": [[13, "src.model_classes.ModelManager.build_features_extractors"]], "get_classifier_to_extractor_str() (in module src.model_classes.modelmanager)": [[13, "src.model_classes.ModelManager.get_classifier_to_extractor_str"]], "manager_execute() (in module src.model_classes.modelmanager)": [[13, "src.model_classes.ModelManager.manager_execute"]], "model_fit_train_predict() (in module src.model_classes.modelmanager)": [[13, "src.model_classes.ModelManager.model_fit_train_predict"]], "reverse_classifier_to_extractor_str() (in module src.model_classes.modelmanager)": [[13, "src.model_classes.ModelManager.reverse_classifier_to_extractor_str"]], "save_model_component() (in module src.model_classes.modelmanager)": [[13, "src.model_classes.ModelManager.save_model_component"]], "src.model_classes.modelmanager": [[13, "module-src.model_classes.ModelManager"]], "evaluate_classifiers() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.evaluate_classifiers"]], "import_classifiers() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.import_classifiers"]], "import_features_extractors() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.import_features_extractors"]], "import_model_objects() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.import_model_objects"]], "perform_prediction() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.perform_prediction"]], "predict_input_from_file() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.predict_input_from_file"]], "preprocess_input() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.preprocess_input"]], "src.model_classes.modelworker": [[14, "module-src.model_classes.ModelWorker"]], "voting_system() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.voting_system"]], "worker_execute() (in module src.model_classes.modelworker)": [[14, "src.model_classes.ModelWorker.worker_execute"]], "staticclassifier (class in src.model_classes.staticclassifier)": [[15, "src.model_classes.StaticClassifier.StaticClassifier"]], "fit_train_evaluate() (src.model_classes.staticclassifier.staticclassifier method)": [[15, "src.model_classes.StaticClassifier.StaticClassifier.fit_train_evaluate"]], "get_confusion_matrix() (src.model_classes.staticclassifier.staticclassifier method)": [[15, "src.model_classes.StaticClassifier.StaticClassifier.get_confusion_matrix"]], "get_model_classes() (src.model_classes.staticclassifier.staticclassifier method)": [[15, "src.model_classes.StaticClassifier.StaticClassifier.get_model_classes"]], "get_model_params() (src.model_classes.staticclassifier.staticclassifier method)": [[15, "src.model_classes.StaticClassifier.StaticClassifier.get_model_params"]], "predict() (src.model_classes.staticclassifier.staticclassifier method)": [[15, "src.model_classes.StaticClassifier.StaticClassifier.predict"]], "predict_probabilities() (src.model_classes.staticclassifier.staticclassifier method)": [[15, "src.model_classes.StaticClassifier.StaticClassifier.predict_probabilities"]], "set_model_params() (src.model_classes.staticclassifier.staticclassifier method)": [[15, "src.model_classes.StaticClassifier.StaticClassifier.set_model_params"]], "short_str() (src.model_classes.staticclassifier.staticclassifier method)": [[15, "src.model_classes.StaticClassifier.StaticClassifier.short_str"]], "src.model_classes.staticclassifier": [[15, "module-src.model_classes.StaticClassifier"]], "tfidfvectorizerfe (class in src.model_classes.tfidfvectorizerfe)": [[16, "src.model_classes.TfidfVectorizerFE.TfidfVectorizerFE"]], "get_extractor_params() (src.model_classes.tfidfvectorizerfe.tfidfvectorizerfe method)": [[16, "src.model_classes.TfidfVectorizerFE.TfidfVectorizerFE.get_extractor_params"]], "get_vocabulary() (src.model_classes.tfidfvectorizerfe.tfidfvectorizerfe method)": [[16, "src.model_classes.TfidfVectorizerFE.TfidfVectorizerFE.get_vocabulary"]], "set_extractor_params() (src.model_classes.tfidfvectorizerfe.tfidfvectorizerfe method)": [[16, "src.model_classes.TfidfVectorizerFE.TfidfVectorizerFE.set_extractor_params"]], "short_str() (src.model_classes.tfidfvectorizerfe.tfidfvectorizerfe method)": [[16, "src.model_classes.TfidfVectorizerFE.TfidfVectorizerFE.short_str"]], "src.model_classes.tfidfvectorizerfe": [[16, "module-src.model_classes.TfidfVectorizerFE"]], "transform_data() (src.model_classes.tfidfvectorizerfe.tfidfvectorizerfe method)": [[16, "src.model_classes.TfidfVectorizerFE.TfidfVectorizerFE.transform_data"]]}})